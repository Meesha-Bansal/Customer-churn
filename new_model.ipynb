{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1739066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f3771f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.best_model = None\n",
    "        self.best_score = 0\n",
    "        self.results = {}\n",
    "\n",
    "    def train_models(self, X_train, y_train, X_val, y_val):\n",
    "        model_grid = {\n",
    "            \"LogisticRegression\": {\n",
    "                \"model\": LogisticRegression(max_iter=1000),\n",
    "                \"params\": {\n",
    "                    \"C\": [0.01, 0.1, 1, 10],\n",
    "                    \"penalty\": ['l2'],\n",
    "                    \"solver\": ['lbfgs']\n",
    "                }\n",
    "            },\n",
    "            \"RandomForest\": {\n",
    "                \"model\": RandomForestClassifier(random_state=42),\n",
    "                \"params\": {\n",
    "                    \"n_estimators\": [100, 200],\n",
    "                    \"max_depth\": [None, 10, 20],\n",
    "                    \"min_samples_split\": [2, 5]\n",
    "                }\n",
    "            },\n",
    "            \"GradientBoosting\": {\n",
    "                \"model\": GradientBoostingClassifier(random_state=42),\n",
    "                \"params\": {\n",
    "                    \"n_estimators\": [100, 200],\n",
    "                    \"learning_rate\": [0.05, 0.1],\n",
    "                    \"max_depth\": [3, 5]\n",
    "                }\n",
    "            },\n",
    "            \"XGBoost\": {\n",
    "                \"model\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "                \"params\": {\n",
    "                    \"n_estimators\": [100, 200],\n",
    "                    \"learning_rate\": [0.05, 0.1],\n",
    "                    \"max_depth\": [3, 5]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        for name, config in model_grid.items():\n",
    "            print(f\"\\nğŸ” Training and tuning {name}...\")\n",
    "            grid_search = GridSearchCV(config['model'], config['params'], cv=3, scoring='f1', n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_pred = best_model.predict(X_val)\n",
    "\n",
    "            acc = accuracy_score(y_val, y_pred)\n",
    "            f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "            self.results[name] = {\n",
    "                \"accuracy\": acc,\n",
    "                \"f1_score\": f1,\n",
    "                \"model\": best_model,\n",
    "                \"classification_report\": classification_report(y_val, y_pred, output_dict=True)\n",
    "            }\n",
    "\n",
    "            if f1 > self.best_score:\n",
    "                self.best_score = f1\n",
    "                self.best_model = best_model\n",
    "\n",
    "    def get_best_model(self):\n",
    "        return self.best_model\n",
    "\n",
    "    def get_results(self):\n",
    "        return pd.DataFrame({\n",
    "            model: {\n",
    "                \"Accuracy\": round(result[\"accuracy\"], 4),\n",
    "                \"F1 Score\": round(result[\"f1_score\"], 4)\n",
    "            }\n",
    "            for model, result in self.results.items()\n",
    "        }).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "058710e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Training and tuning LogisticRegression...\n",
      "\n",
      "ğŸ” Training and tuning RandomForest...\n",
      "\n",
      "ğŸ” Training and tuning GradientBoosting...\n",
      "\n",
      "ğŸ” Training and tuning XGBoost...\n",
      "ğŸ“Š Performance Summary:\n",
      "                    Accuracy  F1 Score\n",
      "LogisticRegression    0.8162    0.6266\n",
      "RandomForest          0.8178    0.6411\n",
      "GradientBoosting      0.8287    0.6605\n",
      "XGBoost               0.8287    0.6615\n",
      "ğŸ“„ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       937\n",
      "           1       0.71      0.62      0.66       347\n",
      "\n",
      "    accuracy                           0.83      1284\n",
      "   macro avg       0.79      0.76      0.77      1284\n",
      "weighted avg       0.82      0.83      0.82      1284\n",
      "\n",
      "ğŸ† Best Model: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load your cleaned data\n",
    "df = pd.read_csv(\"../data/cleaned_churn_data.csv\")  # replace with your actual filename\n",
    "\n",
    "# 2. Separate features and target\n",
    "X = df.drop(columns=['churn'])\n",
    "y = df['churn']\n",
    "\n",
    "# 3. Split into train/validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "trainer = ModelTrainer()\n",
    "trainer.train_models(X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"ğŸ“Š Performance Summary:\")\n",
    "print(trainer.get_results())\n",
    "\n",
    "best_model = trainer.get_best_model()\n",
    "y_pred = best_model.predict(X_val)\n",
    "print(\"ğŸ“„ Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"ğŸ† Best Model:\", best_model.__class__.__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adbeaa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Best model saved as best_churn_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Save to file\n",
    "joblib.dump(best_model, \"best_churn_model.pkl\")\n",
    "print(\"âœ… Best model saved as best_churn_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f557b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
